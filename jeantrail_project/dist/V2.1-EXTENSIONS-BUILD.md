# V2.1 Extensions Build Documentation

## Overview
This document details the implementation of **V2.1 Extensions** features, focusing on security and local-first principles. The build introduces mandatory cryptographic signatures for all extensions and strictly enforces local AI model usage, disabling cloud-based AI integration.

## Implemented Features

### 1. Signed-Only Extensions
**Goal:** Ensure all loaded plugins are verified and trusted by mandating a signature field in the manifest.

**Implementation Details:**
- **File:** `src-tauri/src/plugins.rs`
- **Manifest Update:** Added `signature` field to the `PluginManifest` struct.
- **Validation Logic:** 
  - Updated `validate_plugin_manifest` to reject manifests with empty signatures.
  - Added `verify_plugin_signature` helper function.
  - **Policy:** Signatures must start with the prefix `sig_` (mock verification for this build).
- **Error Handling:** Returns validation errors if the signature is missing or invalid.

**Verification:**
- Valid Manifest: `{ ..., "signature": "sig_valid_hash" }` -> **Accepted**
- Invalid Manifest: `{ ..., "signature": "unsigned_hash" }` -> **Rejected**
- Missing Signature: `{ ... }` -> **Rejected**

### 2. Local AI Enforcement
**Goal:** Disable all cloud-based AI calls and restrict the model registry to local endpoints only to ensure data privacy and air-gapped compatibility.

**Implementation Details:**
- **AI Service (`src-tauri/src/ai.rs`):**
  - **Logic:** Hardcoded `use_cloud_ai = false` in `generate_response`.
  - **Enforcement:** Returns `403 Forbidden` if cloud AI execution is attempted.
  - **Fallback:** Always routes requests to `call_local_llm`.

- **AI Gateway (`src-tauri/src/ai_gateway.rs`):**
  - **Model Registry:** Updated `add_model` to filter incoming model registrations.
  - **Endpoint Validation:** Added `is_local_endpoint` helper.
    - **Allowed:** `localhost`, `127.0.0.1`, `0.0.0.0`, and internal Docker service names.
    - **Blocked:** Public TLDs (`.com`, `.org`, `.net`, `.io`, `.ai`).
  - **Logging:** Logs an error and drops the model if a non-local endpoint is detected.

**Verification:**
- **Generation:** Requests strictly route to local LLM functions. Cloud configurations are ignored.
- **Model Registration:**
  - `http://localhost:11434` -> **Added**
  - `http://api.openai.com` -> **Blocked**

## Build Status
- **Version:** 2.1
- **Kernel Compatibility:** Requires V2.0 Kernel (Deny-by-default networking).
- **Security Level:** High (Signed code + Local data isolation).

---
*Generated by Product Architect Assistant*
